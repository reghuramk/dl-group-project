{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0        Date   Open          Time\n",
      "0           0  11/13/2017  56.81  1.510531e+09\n",
      "1           1  11/14/2017  56.47  1.510618e+09\n",
      "2           2  11/15/2017  56.82  1.510704e+09\n",
      "3           3  11/16/2017  56.92  1.510790e+09\n",
      "4           4  11/17/2017  57.24  1.510877e+09\n",
      "0   2017-11-13\n",
      "1   2017-11-14\n",
      "2   2017-11-15\n",
      "3   2017-11-16\n",
      "4   2017-11-17\n",
      "Name: Date, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "file_path = \"../starbucks_open_7year.csv\"  \n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "print(data.head())\n",
    "\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "print(data['Date'][0:5])\n",
    "data = data.sort_values(by='Date').reset_index(drop=True)\n",
    "\n",
    "X = data['Time'].values.reshape(-1, 1).astype(float)\n",
    "y = data['Open'].values.reshape(-1, 1).astype(float)\n",
    "\n",
    "X_min, X_max = X.min(), X.max()\n",
    "y_min, y_max = y.min(), y.max()\n",
    "\n",
    "X_normalized = (X - X_min) / (X_max - X_min)\n",
    "y_normalized = (y - y_min) / (y_max - y_min)\n",
    "\n",
    "split_index = int(len(X_normalized) * 0.8)\n",
    "X_train, X_test = X_normalized[:split_index], X_normalized[split_index:]\n",
    "y_train, y_test = y_normalized[:split_index], y_normalized[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/reghunotraghu/Documents/college_projects/dl-group-project/.venv/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2715 - mae: 0.4342 - val_loss: 0.0906 - val_mae: 0.2773\n",
      "Epoch 2/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - loss: 0.0308 - mae: 0.1481 - val_loss: 0.0737 - val_mae: 0.2449\n",
      "Epoch 3/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - loss: 0.0284 - mae: 0.1407 - val_loss: 0.0825 - val_mae: 0.2617\n",
      "Epoch 4/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - loss: 0.0289 - mae: 0.1413 - val_loss: 0.0953 - val_mae: 0.2846\n",
      "Epoch 5/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - loss: 0.0268 - mae: 0.1361 - val_loss: 0.0783 - val_mae: 0.2531\n",
      "Epoch 6/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817us/step - loss: 0.0260 - mae: 0.1326 - val_loss: 0.0958 - val_mae: 0.2854\n",
      "Epoch 7/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - loss: 0.0254 - mae: 0.1306 - val_loss: 0.1006 - val_mae: 0.2938\n",
      "Epoch 8/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - loss: 0.0254 - mae: 0.1295 - val_loss: 0.0932 - val_mae: 0.2814\n",
      "Epoch 9/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 0.0250 - mae: 0.1260 - val_loss: 0.0823 - val_mae: 0.2619\n",
      "Epoch 10/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - loss: 0.0248 - mae: 0.1284 - val_loss: 0.0708 - val_mae: 0.2397\n",
      "Epoch 11/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - loss: 0.0223 - mae: 0.1193 - val_loss: 0.0819 - val_mae: 0.2622\n",
      "Epoch 12/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - loss: 0.0225 - mae: 0.1193 - val_loss: 0.0621 - val_mae: 0.2223\n",
      "Epoch 13/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - loss: 0.0229 - mae: 0.1218 - val_loss: 0.0708 - val_mae: 0.2414\n",
      "Epoch 14/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - loss: 0.0209 - mae: 0.1149 - val_loss: 0.0488 - val_mae: 0.1915\n",
      "Epoch 15/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - loss: 0.0220 - mae: 0.1192 - val_loss: 0.0287 - val_mae: 0.1346\n",
      "Epoch 16/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - loss: 0.0202 - mae: 0.1127 - val_loss: 0.0392 - val_mae: 0.1666\n",
      "Epoch 17/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - loss: 0.0207 - mae: 0.1156 - val_loss: 0.0359 - val_mae: 0.1574\n",
      "Epoch 18/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - loss: 0.0200 - mae: 0.1133 - val_loss: 0.0318 - val_mae: 0.1449\n",
      "Epoch 19/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - loss: 0.0196 - mae: 0.1114 - val_loss: 0.0306 - val_mae: 0.1411\n",
      "Epoch 20/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - loss: 0.0188 - mae: 0.1093 - val_loss: 0.0250 - val_mae: 0.1221\n",
      "Epoch 21/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - loss: 0.0196 - mae: 0.1118 - val_loss: 0.0235 - val_mae: 0.1169\n",
      "Epoch 22/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - loss: 0.0184 - mae: 0.1075 - val_loss: 0.0204 - val_mae: 0.1053\n",
      "Epoch 23/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - loss: 0.0172 - mae: 0.1050 - val_loss: 0.0187 - val_mae: 0.0988\n",
      "Epoch 24/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - loss: 0.0169 - mae: 0.1039 - val_loss: 0.0151 - val_mae: 0.0861\n",
      "Epoch 25/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - loss: 0.0190 - mae: 0.1106 - val_loss: 0.0135 - val_mae: 0.0811\n",
      "Epoch 26/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - loss: 0.0173 - mae: 0.1062 - val_loss: 0.0128 - val_mae: 0.0792\n",
      "Epoch 27/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0167 - mae: 0.1027 - val_loss: 0.0123 - val_mae: 0.0781\n",
      "Epoch 28/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - loss: 0.0165 - mae: 0.1039 - val_loss: 0.0109 - val_mae: 0.0778\n",
      "Epoch 29/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822us/step - loss: 0.0171 - mae: 0.1054 - val_loss: 0.0122 - val_mae: 0.0780\n",
      "Epoch 30/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - loss: 0.0168 - mae: 0.1059 - val_loss: 0.0136 - val_mae: 0.0818\n",
      "Epoch 31/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - loss: 0.0163 - mae: 0.1009 - val_loss: 0.0108 - val_mae: 0.0804\n",
      "Epoch 32/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 0.0169 - mae: 0.1066 - val_loss: 0.0151 - val_mae: 0.0867\n",
      "Epoch 33/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - loss: 0.0160 - mae: 0.1006 - val_loss: 0.0124 - val_mae: 0.0785\n",
      "Epoch 34/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - loss: 0.0163 - mae: 0.1025 - val_loss: 0.0108 - val_mae: 0.0804\n",
      "Epoch 35/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 0.0163 - mae: 0.1042 - val_loss: 0.0114 - val_mae: 0.0770\n",
      "Epoch 36/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - loss: 0.0166 - mae: 0.1047 - val_loss: 0.0108 - val_mae: 0.0786\n",
      "Epoch 37/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 0.0169 - mae: 0.1056 - val_loss: 0.0111 - val_mae: 0.0772\n",
      "Epoch 38/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - loss: 0.0161 - mae: 0.1038 - val_loss: 0.0128 - val_mae: 0.0793\n",
      "Epoch 39/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - loss: 0.0161 - mae: 0.1027 - val_loss: 0.0123 - val_mae: 0.0781\n",
      "Epoch 40/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - loss: 0.0153 - mae: 0.0993 - val_loss: 0.0110 - val_mae: 0.0780\n",
      "Epoch 41/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - loss: 0.0157 - mae: 0.1008 - val_loss: 0.0117 - val_mae: 0.0771\n",
      "Epoch 42/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - loss: 0.0166 - mae: 0.1017 - val_loss: 0.0132 - val_mae: 0.0802\n",
      "Epoch 43/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - loss: 0.0149 - mae: 0.0980 - val_loss: 0.0133 - val_mae: 0.0803\n",
      "Epoch 44/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - loss: 0.0158 - mae: 0.0997 - val_loss: 0.0121 - val_mae: 0.0777\n",
      "Epoch 45/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - loss: 0.0163 - mae: 0.1031 - val_loss: 0.0136 - val_mae: 0.0810\n",
      "Epoch 46/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - loss: 0.0164 - mae: 0.1041 - val_loss: 0.0169 - val_mae: 0.0920\n",
      "Epoch 47/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - loss: 0.0142 - mae: 0.0951 - val_loss: 0.0112 - val_mae: 0.0782\n",
      "Epoch 48/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - loss: 0.0159 - mae: 0.1018 - val_loss: 0.0145 - val_mae: 0.0833\n",
      "Epoch 49/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step - loss: 0.0153 - mae: 0.1000 - val_loss: 0.0155 - val_mae: 0.0864\n",
      "Epoch 50/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - loss: 0.0155 - mae: 0.0992 - val_loss: 0.0121 - val_mae: 0.0777\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_dim=1),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1) \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=50, batch_size=32, \n",
    "                    validation_data=(X_test, y_test),\n",
    "                    verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0270 - mae: 0.1289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.04102861508727074, Test MAE: 0.16966617107391357\n"
     ]
    }
   ],
   "source": [
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss}, Test MAE: {mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, my individual contribution focused on building a neural network model that processes the time series data by treating each time instance independently. To achieve this, I used a feedforward neural network (FNN), where each timestamp was treated as an isolated data point, disregarding any temporal dependencies.\n",
    "\n",
    "The process began with data preprocessing, where I converted the Date column into datetime format and sorted the data chronologically to maintain consistency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data = data.sort_values(by='Date').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then extracted the Time column as the feature and Open prices as the target, reshaping and normalizing the data to improve model stability during training.\n",
    "\n",
    "For the model, I built a simple sequential neural network with two hidden layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_dim=1),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I compiled the model using the Adam optimizer and trained it over 50 epochs, evaluating its performance using Mean Absolute Error (MAE). The final test loss and MAE metrics provided a clear indication of the model's accuracy on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflections on my work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through this task, I gained practical experience in preprocessing time series data, applying normalization techniques, and building a basic neural network for regression tasks using Keras. By splitting the data into training and test sets, I ensured the model was evaluated on unseen data, providing a realistic measure of its generalization ability.\n",
    "\n",
    "While this approach does not capture the temporal dependencies inherent in time series data, it serves as a baseline model for comparison with more complex architectures. The expected outcome was to create a straightforward yet effective model that establishes a reference point for evaluating the performance of time series-specific models later in the project."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
